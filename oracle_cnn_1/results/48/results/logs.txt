[CONDUCTOR]: Begin experiment at /mnt/wd500GB/CSC500/csc500-super-repo/csc500-homenet-experiments/oracle_cnn_1/results/48
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 1750], examples_per_second: 977.9426, train_label_loss: 2.8002, 
epoch: 1, [batch: 175 / 1750], examples_per_second: 2880.2553, train_label_loss: 1.8886, 
epoch: 1, [batch: 350 / 1750], examples_per_second: 3459.6503, train_label_loss: 1.5163, 
epoch: 1, [batch: 525 / 1750], examples_per_second: 3840.9220, train_label_loss: 1.2496, 
epoch: 1, [batch: 700 / 1750], examples_per_second: 3850.1842, train_label_loss: 0.9359, 
epoch: 1, [batch: 875 / 1750], examples_per_second: 3870.2462, train_label_loss: 0.9477, 
epoch: 1, [batch: 1050 / 1750], examples_per_second: 3867.7120, train_label_loss: 0.8347, 
epoch: 1, [batch: 1225 / 1750], examples_per_second: 3870.6793, train_label_loss: 0.9365, 
epoch: 1, [batch: 1400 / 1750], examples_per_second: 3857.4539, train_label_loss: 0.6261, 
epoch: 1, [batch: 1575 / 1750], examples_per_second: 3843.5518, train_label_loss: 0.8035, 
=============================================================
epoch: 1, source_val_acc_label: 0.8113, source_val_label_loss: 0.6758, target_val_acc_label: 0.0695, target_val_label_loss: 23.8950, 
=============================================================
New best
epoch: 2, [batch: 1 / 1750], examples_per_second: 1.3016, train_label_loss: 0.7711, 
epoch: 2, [batch: 175 / 1750], examples_per_second: 3843.5273, train_label_loss: 0.7414, 
epoch: 2, [batch: 350 / 1750], examples_per_second: 3873.6783, train_label_loss: 0.7700, 
epoch: 2, [batch: 525 / 1750], examples_per_second: 3873.1430, train_label_loss: 0.7073, 
epoch: 2, [batch: 700 / 1750], examples_per_second: 3873.4713, train_label_loss: 0.5156, 
epoch: 2, [batch: 875 / 1750], examples_per_second: 3873.5307, train_label_loss: 0.5383, 
epoch: 2, [batch: 1050 / 1750], examples_per_second: 3871.0882, train_label_loss: 0.8898, 
epoch: 2, [batch: 1225 / 1750], examples_per_second: 3852.3915, train_label_loss: 0.4621, 
epoch: 2, [batch: 1400 / 1750], examples_per_second: 3844.8186, train_label_loss: 0.4608, 
epoch: 2, [batch: 1575 / 1750], examples_per_second: 3843.8512, train_label_loss: 0.4440, 
=============================================================
epoch: 2, source_val_acc_label: 0.8585, source_val_label_loss: 0.5178, target_val_acc_label: 0.0569, target_val_label_loss: 25.6084, 
=============================================================
New best
epoch: 3, [batch: 1 / 1750], examples_per_second: 7.1979, train_label_loss: 0.3258, 
epoch: 3, [batch: 175 / 1750], examples_per_second: 3832.2119, train_label_loss: 0.3690, 
epoch: 3, [batch: 350 / 1750], examples_per_second: 3830.2797, train_label_loss: 0.4464, 
epoch: 3, [batch: 525 / 1750], examples_per_second: 3831.1100, train_label_loss: 0.4111, 
epoch: 3, [batch: 700 / 1750], examples_per_second: 3831.3262, train_label_loss: 0.4940, 
epoch: 3, [batch: 875 / 1750], examples_per_second: 3831.6853, train_label_loss: 0.4741, 
epoch: 3, [batch: 1050 / 1750], examples_per_second: 3830.3890, train_label_loss: 0.3076, 
epoch: 3, [batch: 1225 / 1750], examples_per_second: 3832.0375, train_label_loss: 0.2723, 
epoch: 3, [batch: 1400 / 1750], examples_per_second: 3831.2868, train_label_loss: 0.4088, 
epoch: 3, [batch: 1575 / 1750], examples_per_second: 3832.3073, train_label_loss: 0.1808, 
=============================================================
epoch: 3, source_val_acc_label: 0.8630, source_val_label_loss: 0.4729, target_val_acc_label: 0.0601, target_val_label_loss: 33.3603, 
=============================================================
New best
epoch: 4, [batch: 1 / 1750], examples_per_second: 7.1846, train_label_loss: 0.1602, 
epoch: 4, [batch: 175 / 1750], examples_per_second: 3833.0110, train_label_loss: 0.2458, 
epoch: 4, [batch: 350 / 1750], examples_per_second: 3834.3161, train_label_loss: 0.2984, 
epoch: 4, [batch: 525 / 1750], examples_per_second: 3836.5285, train_label_loss: 0.3132, 
epoch: 4, [batch: 700 / 1750], examples_per_second: 3835.5067, train_label_loss: 0.2073, 
epoch: 4, [batch: 875 / 1750], examples_per_second: 3833.9478, train_label_loss: 0.3274, 
epoch: 4, [batch: 1050 / 1750], examples_per_second: 3836.0733, train_label_loss: 0.3179, 
epoch: 4, [batch: 1225 / 1750], examples_per_second: 3835.3173, train_label_loss: 0.2476, 
epoch: 4, [batch: 1400 / 1750], examples_per_second: 3831.6206, train_label_loss: 0.3500, 
epoch: 4, [batch: 1575 / 1750], examples_per_second: 3835.1761, train_label_loss: 0.3132, 
=============================================================
epoch: 4, source_val_acc_label: 0.8704, source_val_label_loss: 0.4375, target_val_acc_label: 0.0579, target_val_label_loss: 49.0418, 
=============================================================
New best
epoch: 5, [batch: 1 / 1750], examples_per_second: 7.1806, train_label_loss: 0.2785, 
epoch: 5, [batch: 175 / 1750], examples_per_second: 3829.5538, train_label_loss: 0.1971, 
epoch: 5, [batch: 350 / 1750], examples_per_second: 3831.5903, train_label_loss: 0.2217, 
epoch: 5, [batch: 525 / 1750], examples_per_second: 3834.0182, train_label_loss: 0.2299, 
epoch: 5, [batch: 700 / 1750], examples_per_second: 3834.3446, train_label_loss: 0.2134, 
epoch: 5, [batch: 875 / 1750], examples_per_second: 3833.8167, train_label_loss: 0.2270, 
epoch: 5, [batch: 1050 / 1750], examples_per_second: 3836.0533, train_label_loss: 0.2806, 
epoch: 5, [batch: 1225 / 1750], examples_per_second: 3834.4473, train_label_loss: 0.2331, 
epoch: 5, [batch: 1400 / 1750], examples_per_second: 3836.1347, train_label_loss: 0.3015, 
epoch: 5, [batch: 1575 / 1750], examples_per_second: 3836.4577, train_label_loss: 0.3594, 
=============================================================
epoch: 5, source_val_acc_label: 0.8706, source_val_label_loss: 0.4444, target_val_acc_label: 0.0613, target_val_label_loss: 64.8960, 
=============================================================
epoch: 6, [batch: 1 / 1750], examples_per_second: 7.2011, train_label_loss: 0.1349, 
epoch: 6, [batch: 175 / 1750], examples_per_second: 3813.7412, train_label_loss: 0.1383, 
epoch: 6, [batch: 350 / 1750], examples_per_second: 3815.3793, train_label_loss: 0.1800, 
epoch: 6, [batch: 525 / 1750], examples_per_second: 3815.5503, train_label_loss: 0.2236, 
epoch: 6, [batch: 700 / 1750], examples_per_second: 3815.9161, train_label_loss: 0.1519, 
epoch: 6, [batch: 875 / 1750], examples_per_second: 3815.2773, train_label_loss: 0.1363, 
epoch: 6, [batch: 1050 / 1750], examples_per_second: 3815.4738, train_label_loss: 0.4339, 
epoch: 6, [batch: 1225 / 1750], examples_per_second: 3816.5987, train_label_loss: 0.0920, 
epoch: 6, [batch: 1400 / 1750], examples_per_second: 3815.2990, train_label_loss: 0.2169, 
epoch: 6, [batch: 1575 / 1750], examples_per_second: 3815.5884, train_label_loss: 0.1305, 
=============================================================
epoch: 6, source_val_acc_label: 0.8633, source_val_label_loss: 0.4772, target_val_acc_label: 0.0576, target_val_label_loss: 71.2211, 
=============================================================
epoch: 7, [batch: 1 / 1750], examples_per_second: 7.1810, train_label_loss: 0.1164, 
epoch: 7, [batch: 175 / 1750], examples_per_second: 3817.4320, train_label_loss: 0.0728, 
epoch: 7, [batch: 350 / 1750], examples_per_second: 3813.3522, train_label_loss: 0.0788, 
epoch: 7, [batch: 525 / 1750], examples_per_second: 3812.9266, train_label_loss: 0.0767, 
epoch: 7, [batch: 700 / 1750], examples_per_second: 3814.0472, train_label_loss: 0.1051, 
epoch: 7, [batch: 875 / 1750], examples_per_second: 3813.7398, train_label_loss: 0.1808, 
epoch: 7, [batch: 1050 / 1750], examples_per_second: 3816.9430, train_label_loss: 0.0765, 
epoch: 7, [batch: 1225 / 1750], examples_per_second: 3815.8984, train_label_loss: 0.0593, 
epoch: 7, [batch: 1400 / 1750], examples_per_second: 3819.0692, train_label_loss: 0.0687, 
epoch: 7, [batch: 1575 / 1750], examples_per_second: 3818.2426, train_label_loss: 0.0836, 
=============================================================
epoch: 7, source_val_acc_label: 0.8626, source_val_label_loss: 0.4984, target_val_acc_label: 0.0520, target_val_label_loss: 98.8957, 
=============================================================
epoch: 8, [batch: 1 / 1750], examples_per_second: 7.1693, train_label_loss: 0.0515, 
epoch: 8, [batch: 175 / 1750], examples_per_second: 3814.1246, train_label_loss: 0.0270, 
epoch: 8, [batch: 350 / 1750], examples_per_second: 3815.9182, train_label_loss: 0.0672, 
epoch: 8, [batch: 525 / 1750], examples_per_second: 3815.0818, train_label_loss: 0.0746, 
epoch: 8, [batch: 700 / 1750], examples_per_second: 3814.9315, train_label_loss: 0.0513, 
epoch: 8, [batch: 875 / 1750], examples_per_second: 3815.5971, train_label_loss: 0.0906, 
epoch: 8, [batch: 1050 / 1750], examples_per_second: 3813.8689, train_label_loss: 0.0713, 
epoch: 8, [batch: 1225 / 1750], examples_per_second: 3815.3247, train_label_loss: 0.0694, 
epoch: 8, [batch: 1400 / 1750], examples_per_second: 3814.3671, train_label_loss: 0.0314, 
epoch: 8, [batch: 1575 / 1750], examples_per_second: 3811.3034, train_label_loss: 0.1851, 
=============================================================
epoch: 8, source_val_acc_label: 0.8603, source_val_label_loss: 0.5188, target_val_acc_label: 0.0579, target_val_label_loss: 98.4934, 
=============================================================
epoch: 9, [batch: 1 / 1750], examples_per_second: 7.1763, train_label_loss: 0.0593, 
epoch: 9, [batch: 175 / 1750], examples_per_second: 3815.4640, train_label_loss: 0.0550, 
epoch: 9, [batch: 350 / 1750], examples_per_second: 3812.4259, train_label_loss: 0.0595, 
epoch: 9, [batch: 525 / 1750], examples_per_second: 3815.8004, train_label_loss: 0.0461, 
epoch: 9, [batch: 700 / 1750], examples_per_second: 3816.2096, train_label_loss: 0.0906, 
epoch: 9, [batch: 875 / 1750], examples_per_second: 3814.8851, train_label_loss: 0.0857, 
epoch: 9, [batch: 1050 / 1750], examples_per_second: 3815.0164, train_label_loss: 0.1025, 
epoch: 9, [batch: 1225 / 1750], examples_per_second: 3814.6122, train_label_loss: 0.1240, 
epoch: 9, [batch: 1400 / 1750], examples_per_second: 3813.7481, train_label_loss: 0.0882, 
epoch: 9, [batch: 1575 / 1750], examples_per_second: 3814.8002, train_label_loss: 0.0938, 
=============================================================
epoch: 9, source_val_acc_label: 0.8606, source_val_label_loss: 0.5459, target_val_acc_label: 0.0595, target_val_label_loss: 91.4796, 
=============================================================
epoch: 10, [batch: 1 / 1750], examples_per_second: 7.1744, train_label_loss: 0.0315, 
epoch: 10, [batch: 175 / 1750], examples_per_second: 3815.8493, train_label_loss: 0.0175, 
epoch: 10, [batch: 350 / 1750], examples_per_second: 3816.4099, train_label_loss: 0.1485, 
epoch: 10, [batch: 525 / 1750], examples_per_second: 3818.1830, train_label_loss: 0.0816, 
epoch: 10, [batch: 700 / 1750], examples_per_second: 3813.5983, train_label_loss: 0.0516, 
epoch: 10, [batch: 875 / 1750], examples_per_second: 3813.2228, train_label_loss: 0.0629, 
epoch: 10, [batch: 1050 / 1750], examples_per_second: 3812.1499, train_label_loss: 0.1600, 
epoch: 10, [batch: 1225 / 1750], examples_per_second: 3812.2155, train_label_loss: 0.1066, 
epoch: 10, [batch: 1400 / 1750], examples_per_second: 3813.3676, train_label_loss: 0.0334, 
epoch: 10, [batch: 1575 / 1750], examples_per_second: 3818.5324, train_label_loss: 0.0357, 
=============================================================
epoch: 10, source_val_acc_label: 0.8562, source_val_label_loss: 0.5869, target_val_acc_label: 0.0565, target_val_label_loss: 146.4415, 
=============================================================
epoch: 11, [batch: 1 / 1750], examples_per_second: 7.1752, train_label_loss: 0.0559, 
epoch: 11, [batch: 175 / 1750], examples_per_second: 3814.0862, train_label_loss: 0.0605, 
epoch: 11, [batch: 350 / 1750], examples_per_second: 3818.1721, train_label_loss: 0.0106, 
epoch: 11, [batch: 525 / 1750], examples_per_second: 3818.7150, train_label_loss: 0.0297, 
epoch: 11, [batch: 700 / 1750], examples_per_second: 3812.1802, train_label_loss: 0.0363, 
epoch: 11, [batch: 875 / 1750], examples_per_second: 3813.2064, train_label_loss: 0.0254, 
epoch: 11, [batch: 1050 / 1750], examples_per_second: 3813.4456, train_label_loss: 0.0921, 
epoch: 11, [batch: 1225 / 1750], examples_per_second: 3813.5435, train_label_loss: 0.0485, 
epoch: 11, [batch: 1400 / 1750], examples_per_second: 3812.3897, train_label_loss: 0.0296, 
epoch: 11, [batch: 1575 / 1750], examples_per_second: 3815.1881, train_label_loss: 0.0508, 
=============================================================
epoch: 11, source_val_acc_label: 0.8562, source_val_label_loss: 0.5931, target_val_acc_label: 0.0579, target_val_label_loss: 132.1393, 
=============================================================
epoch: 12, [batch: 1 / 1750], examples_per_second: 7.1786, train_label_loss: 0.0225, 
epoch: 12, [batch: 175 / 1750], examples_per_second: 3817.9422, train_label_loss: 0.0169, 
epoch: 12, [batch: 350 / 1750], examples_per_second: 3817.9139, train_label_loss: 0.0396, 
epoch: 12, [batch: 525 / 1750], examples_per_second: 3814.5979, train_label_loss: 0.0887, 
epoch: 12, [batch: 700 / 1750], examples_per_second: 3814.5412, train_label_loss: 0.0222, 
epoch: 12, [batch: 875 / 1750], examples_per_second: 3813.7806, train_label_loss: 0.0730, 
epoch: 12, [batch: 1050 / 1750], examples_per_second: 3813.1856, train_label_loss: 0.0300, 
epoch: 12, [batch: 1225 / 1750], examples_per_second: 3814.5542, train_label_loss: 0.0727, 
epoch: 12, [batch: 1400 / 1750], examples_per_second: 3815.5646, train_label_loss: 0.0322, 
epoch: 12, [batch: 1575 / 1750], examples_per_second: 3814.7432, train_label_loss: 0.0172, 
=============================================================
epoch: 12, source_val_acc_label: 0.8547, source_val_label_loss: 0.5971, target_val_acc_label: 0.0590, target_val_label_loss: 176.1726, 
=============================================================
epoch: 13, [batch: 1 / 1750], examples_per_second: 7.1732, train_label_loss: 0.0436, 
epoch: 13, [batch: 175 / 1750], examples_per_second: 3814.8744, train_label_loss: 0.0286, 
epoch: 13, [batch: 350 / 1750], examples_per_second: 3814.4542, train_label_loss: 0.0893, 
epoch: 13, [batch: 525 / 1750], examples_per_second: 3814.8683, train_label_loss: 0.0670, 
epoch: 13, [batch: 700 / 1750], examples_per_second: 3814.3532, train_label_loss: 0.0667, 
epoch: 13, [batch: 875 / 1750], examples_per_second: 3816.2168, train_label_loss: 0.0227, 
epoch: 13, [batch: 1050 / 1750], examples_per_second: 3815.2448, train_label_loss: 0.0155, 
epoch: 13, [batch: 1225 / 1750], examples_per_second: 3814.8894, train_label_loss: 0.1109, 
epoch: 13, [batch: 1400 / 1750], examples_per_second: 3814.7550, train_label_loss: 0.0102, 
epoch: 13, [batch: 1575 / 1750], examples_per_second: 3814.1172, train_label_loss: 0.0809, 
=============================================================
epoch: 13, source_val_acc_label: 0.8545, source_val_label_loss: 0.6203, target_val_acc_label: 0.0584, target_val_label_loss: 185.7055, 
=============================================================
epoch: 14, [batch: 1 / 1750], examples_per_second: 7.1775, train_label_loss: 0.0514, 
epoch: 14, [batch: 175 / 1750], examples_per_second: 3814.4479, train_label_loss: 0.0302, 
epoch: 14, [batch: 350 / 1750], examples_per_second: 3815.3963, train_label_loss: 0.0149, 
epoch: 14, [batch: 525 / 1750], examples_per_second: 3813.0101, train_label_loss: 0.0363, 
epoch: 14, [batch: 700 / 1750], examples_per_second: 3815.7037, train_label_loss: 0.0224, 
epoch: 14, [batch: 875 / 1750], examples_per_second: 3815.7834, train_label_loss: 0.0366, 
epoch: 14, [batch: 1050 / 1750], examples_per_second: 3814.2851, train_label_loss: 0.0155, 
epoch: 14, [batch: 1225 / 1750], examples_per_second: 3816.3231, train_label_loss: 0.0124, 
epoch: 14, [batch: 1400 / 1750], examples_per_second: 3815.2153, train_label_loss: 0.0325, 
epoch: 14, [batch: 1575 / 1750], examples_per_second: 3815.0143, train_label_loss: 0.0268, 
=============================================================
epoch: 14, source_val_acc_label: 0.8601, source_val_label_loss: 0.6208, target_val_acc_label: 0.0583, target_val_label_loss: 180.4451, 
=============================================================
epoch: 15, [batch: 1 / 1750], examples_per_second: 7.1793, train_label_loss: 0.0158, 
epoch: 15, [batch: 175 / 1750], examples_per_second: 3815.1576, train_label_loss: 0.0190, 
epoch: 15, [batch: 350 / 1750], examples_per_second: 3814.7850, train_label_loss: 0.1339, 
epoch: 15, [batch: 525 / 1750], examples_per_second: 3816.2784, train_label_loss: 0.0117, 
epoch: 15, [batch: 700 / 1750], examples_per_second: 3815.0533, train_label_loss: 0.0233, 
epoch: 15, [batch: 875 / 1750], examples_per_second: 3812.9482, train_label_loss: 0.0323, 
epoch: 15, [batch: 1050 / 1750], examples_per_second: 3815.8572, train_label_loss: 0.0081, 
epoch: 15, [batch: 1225 / 1750], examples_per_second: 3815.2854, train_label_loss: 0.0538, 
epoch: 15, [batch: 1400 / 1750], examples_per_second: 3814.7144, train_label_loss: 0.1057, 
epoch: 15, [batch: 1575 / 1750], examples_per_second: 3813.0566, train_label_loss: 0.0504, 
=============================================================
epoch: 15, source_val_acc_label: 0.8499, source_val_label_loss: 0.6526, target_val_acc_label: 0.0462, target_val_label_loss: 150.8865, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.864375 Target Test Label Accuracy: 0.058258333333333336
Source Val Label Accuracy: 0.8704166666666666 Target Val Label Accuracy: 0.0578625
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
